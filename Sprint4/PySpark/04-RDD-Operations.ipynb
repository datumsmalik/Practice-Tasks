{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb47b03-539b-4560-98d6-5ec7c34672d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the PySpark environment variables\n",
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/home/user5/Downloads/spark\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = 'lab'\n",
    "os.environ['PYSPARK_PYTHON'] = 'python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ebd54a-efc6-4ba9-aef5-b2b125688dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e21e168-1142-4b1c-8670-c260de19cdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"RDD-Demo\").getOrCreate()\n",
    "\n",
    "##getOrCreate() → Reuse existing SparkSession or create a new one (prevents Jupyter errors).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7959b2-fe2d-443c-bf25-8d217d78db83",
   "metadata": {},
   "source": [
    "RDD = Resilient Distributed Dataset\n",
    "It’s Spark’s core data structure\n",
    "\n",
    "Why “Resilient”?\n",
    "Because it can recover lost data automatically if a worker fails.\n",
    "\n",
    "Why “Distributed”?\n",
    "Because the data is split into partitions across the cluster.\n",
    "\n",
    "Why “Dataset”?\n",
    "Because it’s just a collection of records (like a list in Python).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854c7262-b859-4a2e-a320-08d9bf4424e7",
   "metadata": {},
   "source": [
    "How to create RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "872da2c0-12f7-44a2-afed-98c44ffe3658",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [1, 2, 3, 4, 5]\n",
    "rdd = spark.sparkContext.parallelize(numbers)\n",
    "\n",
    "#Converts the Python list into a distributed dataset (RDD = Resilient Dis#tributed Dataset).\n",
    "\n",
    "#Spark splits the list into partitions so it can process data in parallel.\n",
    "#spark.sparkContext is the lower-level API that works directly with RDDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd9e9c5c-802b-4969-91ec-5736a87f2f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect action: Retrieve all elements of the RDD\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ffcd673-0366-4d04-9174-173032bfbb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an RDD from a list of tuples\n",
    "data = [(\"Alice\", 25), (\"Bob\", 30), (\"Charlie\", 35), (\"Alice\", 40)]\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36036020-2635-48d9-bece-9824a6d357a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All elements of the rdd:  [('Alice', 25), ('Bob', 30), ('Charlie', 35), ('Alice', 40)]\n"
     ]
    }
   ],
   "source": [
    "# Collect action: Retrieve all elements of the RDD\n",
    "print(\"All elements of the rdd: \", rdd.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd891e5-d9e3-48ca-a75c-a8ceffebb01e",
   "metadata": {},
   "source": [
    "RDDs Operation: Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "483c0133-5103-4195-968d-07d2f11a31f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of elements in rdd:  4\n"
     ]
    }
   ],
   "source": [
    "# Count action: Count the number of elements in the RDD\n",
    "count = rdd.count()\n",
    "print(\"The total number of elements in rdd: \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0872c06-deab-49dd-8f62-3899d355f67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of the rdd:  ('Alice', 25)\n"
     ]
    }
   ],
   "source": [
    "# First action: Retrieve the first element of the RDD\n",
    "first_element = rdd.first()\n",
    "print(\"The first element of the rdd: \", first_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c3efb1a-9990-4b3c-a4ed-8a486510421d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first two elements of the rdd:  [('Alice', 25), ('Bob', 30)]\n"
     ]
    }
   ],
   "source": [
    "# Take action: Retrieve the n elements of the RDD\n",
    "taken_elements = rdd.take(2)\n",
    "print(\"The first two elements of the rdd: \", taken_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a439a15d-dc2c-401d-bd02-d33dfa554ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "('Bob', 30)\n",
      "('Alice', 25)\n",
      "('Alice', 40)\n",
      "('Charlie', 35)\n"
     ]
    }
   ],
   "source": [
    "# Foreach action: Print each element of the RDD\n",
    "rdd.foreach(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf1bad-0d82-4013-91c2-a148e4794e11",
   "metadata": {},
   "source": [
    "RDDs Operation: Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aba75c75-21c0-4c00-a21c-cb20631f42db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map transformation: Convert name to uppercase\n",
    "mapped_rdd = rdd.map(lambda x: (x[0].upper(), x[1]))\n",
    "#Applies a function to each element of the RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05651309-3ee4-46a0-863f-bde1b2cccae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rdd with uppercease name:  [('ALICE', 25), ('BOB', 30), ('CHARLIE', 35), ('ALICE', 40)]\n"
     ]
    }
   ],
   "source": [
    "result = mapped_rdd.collect()\n",
    "print(\"rdd with uppercease name: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae215081-37f4-4b15-9a2a-f4bfaf5ae044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Charlie', 35), ('Alice', 40)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter transformation: Filter records where age is greater than 30\n",
    "filtered_rdd = rdd.filter(lambda x: x[1] > 30)\n",
    "filtered_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb1407c4-0a97-44fe-89da-5cb7a02f7f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Charlie', 35), ('Alice', 65), ('Bob', 30)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ReduceByKey transformation: Calculate the total age for each name\n",
    "reduced_rdd = rdd.reduceByKey(lambda x, y: x + y) # reduceByKey Pair RDDs \n",
    "reduced_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95a9023a-d866-478b-83b7-e1788eaab9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alice', 40), ('Charlie', 35), ('Bob', 30), ('Alice', 25)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SortBy transformation: Sort the RDD by age in descending order\n",
    "sorted_rdd = rdd.sortBy(lambda x: x[1], ascending=False)\n",
    "sorted_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f683ac1-acfc-43a1-878d-9d7e04e84854",
   "metadata": {},
   "source": [
    "Save RDDs to text file and read RDDs from text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc2fe76a-3cd3-4c03-830b-db51cdf839c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save action: Save the RDD to a text file\n",
    "rdd.saveAsTextFile(\"output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7fb754c-f2d0-4f76-9914-ae8aa73137dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"('Bob', 30)\", \"('Alice', 40)\", \"('Alice', 25)\", \"('Charlie', 35)\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create rdd from text file\n",
    "rdd_text = spark.sparkContext.textFile(\"output.txt\")\n",
    "rdd_text.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dca7faef-1d3c-4170-8438-80d548b62c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d360004-b6d6-4cd8-aecb-38a32772817c",
   "metadata": {},
   "source": [
    "Why “Lazy”?\n",
    "In Spark, transformations don’t run immediately.\n",
    "\n",
    "They just build a plan of what to do.\n",
    "\n",
    "The plan only runs when you call an action.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c5584-4490-4c57-b42c-14442ac10ee0",
   "metadata": {},
   "source": [
    "Transformations (lazy → return a new RDD)\n",
    "\n",
    "map() → Apply a function to each element.\n",
    "\n",
    "flatMap() → Apply a function & flatten results.\n",
    "\n",
    "filter() → Keep only elements matching a condition.\n",
    "\n",
    "reduceByKey() → Combine values with the same key using a function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce6e55-dab6-47f7-a3e6-51df8843717c",
   "metadata": {},
   "source": [
    "Actions (trigger execution → return a value to driver or write data)\n",
    "collect() → Bring all elements to the driver as a list.\n",
    "\n",
    "count() → Count number of elements.\n",
    "\n",
    "first() → Get the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10fe5b-fcdb-411c-9bc1-209b46ec854b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
