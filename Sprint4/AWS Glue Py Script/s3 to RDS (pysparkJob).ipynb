{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "#configure btata he k job kese run krni he \n\n%%configure\n{\n  \"--enable-spark-ui\": \"true\",\n  \"--spark-event-logs-path\": \"s3://sufis-bucket/output/lab3/sparklog/\",\n  \"max_retries\": \"0\"\n}\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "The following configurations have been updated: {'--enable-spark-ui': 'true', '--spark-event-logs-path': 's3://sufis-bucket/output/lab3/sparklog/', 'max_retries': '0'}\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Importing Glue and Spark libraries\nimport sys #In Glue jobs, it’s used when reading parameters passed at job runtime\nfrom awsglue.transforms import * #This imports Glue’s built-in data transformation helpers.\nfrom awsglue.utils import getResolvedOptions # Special Glue helper for reading parameters you pass when starting a Glue job\nfrom pyspark.context import SparkContext #starts the Spark engine.\nfrom awsglue.context import GlueContext # adds Glue features on top of Spark.\nfrom awsglue.job import Job #tells Glue you’re running a Glue job.\nfrom awsglue.dynamicframe import DynamicFrame #Glue’s special table format (more flexible than DataFrame).\n\n\nimport boto3 #lets you call AWS services from Python\nfrom pprint import pprint # prints results in a nice readable way.\n\nfrom datetime import datetime #works with timestamps.\n\n# Start Spark/Glue Context\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Trying to create a Glue session for the kernel.\nSession Type: glueetl\nSession ID: fe8b7c03-6823-4c60-b162-e82b97a02975\nApplying the following default arguments:\n--glue_kernel_version 1.0.8\n--enable-glue-datacatalog true\n--enable-spark-ui true\n--spark-event-logs-path s3://sufis-bucket/output/lab3/sparklog/\n--max_retries 0\nWaiting for session fe8b7c03-6823-4c60-b162-e82b97a02975 to get into ready status...\nSession fe8b7c03-6823-4c60-b162-e82b97a02975 has been created.\n\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "from pyspark.context import SparkContext \nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\nfrom awsglue.dynamicframe import DynamicFrame\n\n# Glue context\nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\n\n# Glue Catalog details\ncatalog_db = \" pgdatabase-1\"       # Your Glue catalog database name\ncatalog_table = \"sampledata\"      # Your Glue catalog table name\n\n# PostgreSQL connection details\nrds_host = \"postgres.clwcyeea822i.eu-north-1.rds.amazonaws.com\"\nrds_port = \"5432\"\nrds_db = \"postgres\"\nrds_user = \"postgres\"  # Replace with your actual RDS username\nrds_password = \"Paki$tani123$$$\"\ntarget_table = \"sampledata_target\"\n\n\n# Read from Glue Catalog table\ndyf = glueContext.create_dynamic_frame.from_catalog(\n    database=catalog_db,\n    table_name=catalog_table\n)\n#DynamicFrame = AWS Glue’s friendly format for messy data.\n\n#DataFrame = Spark’s strict format for clean data and analytics.\n\n# Convert DynamicFrame -- DataFrame\ndf = dyf.toDF()\n\ndf.show(5)\ndf.printSchema()\n\n# JDBC URL (JDBC 1 driver he jo k talk to any database provide krta he )\n\njdbc_url = f\"jdbc:postgresql://{rds_host}:{rds_port}/{rds_db}\"\n\n\n# Write to RDS PostgreSQL\ndf.write \\\n    .format(\"jdbc\") \\\n    .option(\"url\", jdbc_url) \\\n    .option(\"dbtable\", target_table) \\\n    .option(\"user\", rds_user) \\\n    .option(\"password\", rds_password) \\\n    .option(\"driver\", \"org.postgresql.Driver\") \\\n    .mode(\"append\") \\\n    .save()\n\nprint(\" Data successfully loaded into PostgreSQL RDS from Glue Catalog table\")\n",
			"metadata": {
				"trusted": true,
				"tags": []
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "+---+-----+---+\n| id| name|age|\n+---+-----+---+\n|  1|  Ali| 25|\n|  2|Ahmed| 30|\n|  3| Sara| 28|\n+---+-----+---+\n\nroot\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- age: long (nullable = true)\n\n✅ Data successfully loaded into PostgreSQL RDS from Glue Catalog table\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": []
		}
	]
}