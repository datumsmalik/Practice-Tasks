[32m2025-07-23 18:18:08 +0500[0m - dagster - [34mDEBUG[0m - dlt_data_pipeline_job - f16ff2d7-58ab-4125-bd29-e398c3fca33f - 337603 - LOGS_CAPTURED - Started capturing logs in process (pid: 337603).
[32m2025-07-23 18:18:08 +0500[0m - dagster - [34mDEBUG[0m - dlt_data_pipeline_job - f16ff2d7-58ab-4125-bd29-e398c3fca33f - 337603 - dlt_pipeline_op - STEP_START - Started execution of step "dlt_pipeline_op".
/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (21.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == "pandas"'
  warn_incompatible_dep(
2025-07-23 18:18:15,073|[ERROR]|337603|139504631412416|dlt|load.py|w_run_job:247|Terminal exception in job processed_data.10f9f4ceb8.parquet in file /home/user5/.dlt/pipelines/dagster_dlt_pipeline/load/normalized/1753276691.52828/started_jobs/processed_data.10f9f4ceb8.0.parquet
Traceback (most recent call last):
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/destinations/sql_client.py", line 443, in _wrap_gen
    return (yield from f(self, *args, **kwargs))
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/destinations/impl/snowflake/sql_client.py", line 138, in execute_query
    raise outer
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/destinations/impl/snowflake/sql_client.py", line 130, in execute_query
    curr.execute(query, db_args, num_statements=0)
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1137, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 279, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 334, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/snowflake/connector/errors.py", line 210, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002003 (02000): SQL compilation error:
Stage 'ETL_DB.PUBLIC."%PROCESSED_DATA"' does not exist or not authorized.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/common/destination/client.py", line 406, in run_managed
    self.run()
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/destinations/impl/snowflake/snowflake.py", line 109, in run
    self._sql_client.execute_sql(
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/destinations/impl/snowflake/sql_client.py", line 116, in execute_sql
    with self.execute_query(sql, *args, **kwargs) as curr:
  File "/usr/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/destinations/sql_client.py", line 445, in _wrap_gen
    raise self._make_database_exception(ex)
dlt.destinations.exceptions.DatabaseUndefinedRelation: 002003 (02000): SQL compilation error:
Stage 'ETL_DB.PUBLIC."%PROCESSED_DATA"' does not exist or not authorized.
2025-07-23 18:18:15,080|[ERROR]|337603|139505575196096|dlt|load.py|complete_jobs:413|Job for processed_data.10f9f4ceb8.parquet failed terminally in load 1753276691.52828 with message 002003 (02000): SQL compilation error:
Stage 'ETL_DB.PUBLIC."%PROCESSED_DATA"' does not exist or not authorized.
[32m2025-07-23 18:18:15 +0500[0m - dagster - [34mERROR[0m - [31mdlt_data_pipeline_job - f16ff2d7-58ab-4125-bd29-e398c3fca33f - 337603 - dlt_pipeline_op - STEP_FAILURE - Execution of step "dlt_pipeline_op" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "dlt_pipeline_op"::

dlt.pipeline.exceptions.PipelineStepFailed: Pipeline execution failed at `step=load` with exception:

<class 'dlt.load.exceptions.LoadClientJobFailed'>
Job with `job_id=processed_data.10f9f4ceb8.parquet` and `load_id=1753276691.52828` failed terminally with message: 002003 (02000): SQL compilation error:
Stage 'ETL_DB.PUBLIC."%PROCESSED_DATA"' does not exist or not authorized.. The package is aborted and cannot be retried.

Stack Trace:
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 57, in op_execution_error_boundary
    yield
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 392, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 137, in _coerce_op_compute_fn_to_iterator
    result = invoke_compute_fn(
             ^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 117, in invoke_compute_fn
    return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
                                                                    ^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/dagster_demo/pipeline.py", line 59, in dlt_pipeline_op
    load_info = pipeline.run(df, table_name="processed_data")
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 231, in _wrap
    step_info = f(self, *args, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 280, in _wrap
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 744, in run
    return self.load(destination, dataset_name, credentials=credentials)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 231, in _wrap
    step_info = f(self, *args, **kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 171, in _wrap
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 280, in _wrap
    return f(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 607, in load
    raise PipelineStepFailed(

The above exception was caused by the following exception:
dlt.load.exceptions.LoadClientJobFailed: Job with `job_id=processed_data.10f9f4ceb8.parquet` and `load_id=1753276691.52828` failed terminally with message: 002003 (02000): SQL compilation error:
Stage 'ETL_DB.PUBLIC."%PROCESSED_DATA"' does not exist or not authorized.. The package is aborted and cannot be retried.

Stack Trace:
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/pipeline/pipeline.py", line 601, in load
    runner.run_pool(load_step.config, load_step)
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py", line 203, in run_pool
    while _run_func():
          ^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/common/runners/pool_runner.py", line 196, in _run_func
    run_metrics = run_f.run(cast(TExecutor, pool))
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/load/load.py", line 638, in run
    self.load_single_package(load_id, schema)
  File "/home/user5/Desktop/Practice/Sprint3/dagster_demo/venv/lib/python3.12/site-packages/dlt/load/load.py", line 597, in load_single_package
    raise pending_exception
[0m
